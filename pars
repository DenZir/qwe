import requests  
from bs4 import BeautifulSoup  
import re  
from urllib.parse import urljoin  

def fetch_video_links(url):  
    try:  
        # Отправка GET-запроса к URL  
        response = requests.get(url)  
        response.raise_for_status()  # Проверка статуса ответа  

        # Парсинг контента страницы  
        soup = BeautifulSoup(response.text, 'html.parser')  

        # Список для хранения видео ссылок  
        video_links = []  

        # Поиск видео ссылок в <a> тегах  
        for link in soup.find_all('a', href=True):  
            href = link['href']  
            # Проверка на наличие видео-расширения  
            if re.search(r'\.(mp4|avi|mov|wmv|mkv|flv|webm)$', href, re.IGNORECASE):  
                video_links.append(urljoin(url, href))  # Делаем абсолютную ссылку  

        # Поиск видео в <video> тегах и их <source>  
        for video in soup.find_all('video'):  
            for source in video.find_all('source', src=True):  
                video_links.append(urljoin(url, source['src']))  # Делаем абсолютную ссылку  

        return video_links  

    except requests.RequestException as e:  
        print(f"Ошибка при выполнении запроса: {e}")  
        return []  

def main():  
    # Введи URL веб-сайта, с которого необходимо извлечь видео ссылки  
    url = input("Введите URL (HTTPS): ")  

    # Получаем и выводим ссылки на видео  
    video_links = fetch_video_links(url)  

    if video_links:  
        print("Найденные видео ссылки:")  
        for i, video_link in enumerate(video_links, start=1):  
            print(f"{i}. {video_link}")  
    else:  
        print("Видео ссылки не найдены.")  

if __name__ == "__main__":  
    main()  
